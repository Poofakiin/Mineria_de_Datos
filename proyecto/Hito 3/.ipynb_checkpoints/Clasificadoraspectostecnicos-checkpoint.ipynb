{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d04519a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7884/3842427272.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_tecnico\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'genre'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lyrics'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_tecnico\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df_tecnico = df[['genre', 'lyrics', 'danceability', 'loudness', 'acousticness', 'instrumentalness', 'valence', 'energy']]\n",
    "df_tecnico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac4438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esto nos da una idea de que se deberan aplicar tecnicas de subsampling o de oversampling\n",
    "df_tecnico['genre'].value_counts()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6fad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df_tecnico['genre'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_tecnico, y, test_size=0.25, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeda578",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7446a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[X_test.columns.difference([\"genre\"])].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78daea54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling sobre el grupo de training\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "idx = np.random.choice(X_train[X_train['genre'] == \"country\"].index, size=1197)\n",
    "data_oversampled = pd.concat([X_train, X_train.iloc[idx]])\n",
    "\n",
    "idx = np.random.choice(X_train[X_train['genre'] == \"blues\"].index, size=1828)\n",
    "data_oversampled = pd.concat([data_oversampled, X_train.iloc[idx]])\n",
    "\n",
    "idx = np.random.choice(X_train[X_train['genre'] == \"rock\"].index, size=2256)\n",
    "data_oversampled = pd.concat([data_oversampled, X_train.iloc[idx]])\n",
    "\n",
    "idx = np.random.choice(X_train[X_train['genre'] == \"jazz\"].index, size=2397)\n",
    "data_oversampled = pd.concat([data_oversampled, X_train.iloc[idx]])\n",
    "\n",
    "idx = np.random.choice(X_train[X_train['genre'] == \"reggae\"].index, size=3407)\n",
    "data_oversampled = pd.concat([data_oversampled, X_train.iloc[idx]])\n",
    "\n",
    "idx = np.random.choice(X_train[X_train['genre'] == \"hip hop\"].index, size=4603)\n",
    "data_oversampled = pd.concat([data_oversampled, X_train.iloc[idx]])\n",
    "\n",
    "print(\"Data oversampled on genre`s classes\")\n",
    "print(data_oversampled['genre'].value_counts())\n",
    "print()\n",
    "\n",
    "\n",
    "#subsampling sobre el grupo de training\n",
    "\n",
    "idx = np.random.choice(X_train.loc[X_train.genre == \"pop\"].index, size=4603, replace=False)\n",
    "data_subsampled = X_train.drop(X_train.iloc[idx].index)\n",
    "\n",
    "idx = np.random.choice(X_train.loc[X_train.genre == \"country\"].index, size=3406, replace=False)\n",
    "data_subsampled = data_subsampled.drop(X_train.iloc[idx].index)\n",
    "\n",
    "idx = np.random.choice(X_train.loc[X_train.genre == \"blues\"].index, size=2775, replace=False)\n",
    "data_subsampled = data_subsampled.drop(X_train.iloc[idx].index)\n",
    "\n",
    "idx = np.random.choice(X_train.loc[X_train.genre == \"rock\"].index, size=2347, replace=False)\n",
    "data_subsampled = data_subsampled.drop(X_train.iloc[idx].index)\n",
    "\n",
    "idx = np.random.choice(X_train.loc[X_train.genre == \"jazz\"].index, size=2206, replace=False)\n",
    "data_subsampled = data_subsampled.drop(X_train.iloc[idx].index)\n",
    "\n",
    "idx = np.random.choice(X_train.loc[X_train.genre == \"reggae\"].index, size=1196, replace=False)\n",
    "data_subsampled = data_subsampled.drop(X_train.iloc[idx].index)\n",
    "print(\"Data subsampled on genre`s classes\")\n",
    "print(data_subsampled['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85ef2b",
   "metadata": {},
   "source": [
    "Generamos ahora los conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5df6185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datos para testing\n",
    "X_test = X_test[X_test.columns.difference([\"genre\"])].values # todo hasta la penultima columna\n",
    "y_test = y_test\n",
    "\n",
    "# datos entrenamiento \"originales\"\n",
    "X_train = X_train[X_train.columns.difference([\"genre\"])].values \n",
    "y_train = y_train\n",
    "\n",
    "df_tecnico[df_tecnico.columns.difference(['genre'])].values\n",
    "# datos entrenamiento \"oversampleados\" \n",
    "X_over = data_oversampled[data_oversampled.columns.difference([\"genre\"])].values\n",
    "y_over = data_oversampled[\"genre\"].values\n",
    "\n",
    "# datos entrenamiento \"subsampleados\"\n",
    "X_subs = data_subsampled[data_subsampled.columns.difference([\"genre\"])].values\n",
    "y_subs = data_subsampled[\"genre\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d6b94",
   "metadata": {},
   "source": [
    "Ahora se aplicaran 3 modelos de clasificacion a los datos seleccionados, para esto se ocupara GridSearchCV con el fin de encontrar los parametros optimos para estos modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33831b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos originales\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier #kNN\n",
    "\n",
    "#Kmeans parameters\n",
    "\n",
    "tuned_parameters = {'n_neighbors': [ 2, 3, 4, 5, 10], \n",
    "                    'weights': ['uniform','distance']}\n",
    "score = 'precision' \n",
    "\n",
    "#KMEAN Original values\n",
    "\n",
    "clf_kmeans_o = GridSearchCV(KNeighborsClassifier(), \n",
    "                   param_grid=tuned_parameters, \n",
    "                   cv=5,\n",
    "                   scoring=score)\n",
    "clf_kmeans_o.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf_kmeans_o.best_params_)\n",
    " \n",
    "y_pred_kmeans_o = clf_kmeans_o.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_kmeans_o))\n",
    "\n",
    "#KMEAN Subsampled values\n",
    "\n",
    "clf_kmeans_s = GridSearchCV(KNeighborsClassifier(), \n",
    "                   param_grid=tuned_parameters, \n",
    "                   cv=5,\n",
    "                   scoring=score)\n",
    "clf_kmeans_s.fit(X_subs, y_subs)\n",
    "\n",
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf_kmeans_s.best_params_)\n",
    " \n",
    "y_pred_kmeans_s = clf_kmeans_s.predict(X_test)\n",
    "\n",
    "#KMEAN Oversampled values\n",
    "\n",
    "clf_kmeans_over = GridSearchCV(KNeighborsClassifier(), \n",
    "                   param_grid=tuned_parameters, \n",
    "                   cv=5,\n",
    "                   scoring=score)\n",
    "clf_kmeans_over.fit(X_over, y_over)\n",
    "\n",
    "\n",
    " \n",
    "y_pred_kmeans_over = clf_kmeans_over.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f18a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf_kmeans_over.best_params_)\n",
    "print(\"KMeans models: \")\n",
    "print(\"Original data:\")\n",
    "print(classification_report(y_test, y_pred_kmeans_o))\n",
    "print(\"Subsample Data:\")\n",
    "print(classification_report(y_test, y_pred_kmeans_s))\n",
    "print(\"Oversample Data:\")\n",
    "print(classification_report(y_test, y_pred_kmeans_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparacion de modelos de Decision Tree\n",
    "\n",
    "\n",
    "#Decision Tree parameters\n",
    "tuned_parameters = {'criterion': ['gini','entropy'], \n",
    "                    'max_depth': [3,5,7,10]}\n",
    "score = 'f1' \n",
    "\n",
    "#Decision Tree Original values\n",
    "clf_decision_o = GridSearchCV(DecisionTreeClassifier(), \n",
    "                   param_grid=tuned_parameters, \n",
    "                   cv=10,\n",
    "                   scoring=score)\n",
    "\n",
    "clf_decision_o.fit(X_train, y_train)\n",
    "y_pred_decision_o = clf_decision_o.predict(X_test)\n",
    "\n",
    "#Decision Tree Subsampled values\n",
    "clf_decision_sub = GridSearchCV(DecisionTreeClassifier(), \n",
    "                   param_grid=tuned_parameters, \n",
    "                   cv=10,\n",
    "                   scoring=score)\n",
    "\n",
    "clf_decision_sub.fit(X_subs, y_subs)\n",
    "y_pred_decision_sub = clf_decision_sub.predict(X_test)\n",
    "\n",
    "#Decision Tree Oversampled values\n",
    "clf_decision_over = GridSearchCV(DecisionTreeClassifier(), \n",
    "                   param_grid=tuned_parameters, \n",
    "                   cv=10,\n",
    "                   scoring=score)\n",
    "\n",
    "clf_decision_over.fit(X_over, y_over)\n",
    "y_pred_decision_over = clf_decision_over.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb13b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf_decision_o.best_params_)\n",
    "print(\"DecisionTree models: \")\n",
    "print(\"Original data:\")\n",
    "print(classification_report(y_test, y_pred_decision_o))\n",
    "print(\"Subsample Data:\")\n",
    "print(classification_report(y_test, y_pred_decision_sub))\n",
    "print(\"Oversample Data:\")\n",
    "print(classification_report(y_test, y_pred_decision_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec8c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparacion de modelos de SVC\n",
    "\n",
    "#Decision Tree parameters\n",
    "tuned_parameters = {\"kernel\" : [\"linear\", \"poly\", \"rbf\", \"sigmoid\", \"precomputed\"], \n",
    "                    'degree': [3,5,7,10]}\n",
    "score = 'f1' \n",
    "\n",
    "#Decision Tree Original values\n",
    "clf_svc_o = GridSearchCV(SVC(), \n",
    "                   param_grid=tuned_parameters, \n",
    "                   cv=10,\n",
    "                   scoring=score)\n",
    "\n",
    "clf_svc_o.fit(X_train, y_train)\n",
    "y_pred_svc_o = clf_svc_o.predict(X_test)\n",
    "\n",
    "#Decision Tree Subsampled values\n",
    "clf_svc_sub = GridSearchCV(SVC(), \n",
    "                   param_grid=tuned_parameters, \n",
    "                   cv=10,\n",
    "                   scoring=score)\n",
    "\n",
    "clf_svc_sub.fit(X_subs, y_subs)\n",
    "y_pred_svc_sub = clf_svc_sub.predict(X_test)\n",
    "\n",
    "#Decision Tree Oversampled values\n",
    "clf_svc_over = GridSearchCV(SVC(), \n",
    "                   param_grid=tuned_parameters, \n",
    "                   cv=10,\n",
    "                   scoring=score)\n",
    "\n",
    "clf_svc_over.fit(X_over, y_over)\n",
    "y_pred_svc_over = clf_svc_over.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62714b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "# Compute confusion matrix. By default is not normalized (normalize=None)\n",
    "# If necessary change 'y_pred' according to your variable name\n",
    "cm = confusion_matrix(y_test, y_pred_kmeans_s)\n",
    "\n",
    "# Only use the labels that appear in the data\n",
    "classes = unique_labels(y_test, y_pred_kmeans_s)\n",
    "\n",
    "df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "\n",
    "g = sns.heatmap(df, annot=True, cmap=\"Blues\")\n",
    "g.set_yticklabels(g.get_yticklabels(), rotation=0)\n",
    "\n",
    "plt.title('Confusion matrix \\n')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "\n",
    "plt.autoscale()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
